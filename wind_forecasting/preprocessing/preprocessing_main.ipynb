{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ahenry-39583s:57516] shmem: mmap: an error occurred while determining whether or not /var/folders/15/zl_rr3g10_b5j7bk42pk4dgr4qydb3/T//ompi.ahenry-39583s.159331683/jf.0/2292121600/sm_segment.ahenry-39583s.159331683.889f0000.0 could be created.\n",
      "/Users/ahenry/miniconda3/envs/wind_forecasting_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-10-16 17:28:27,027 - WARNING - /Users/ahenry/miniconda3/envs/wind_forecasting_env/lib/python3.12/site-packages/h5pyd/version.py:23: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  _exp = _sv(version)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ! module load mambaforge\n",
    "# ! mamba create -n wind_forecasting_env python=3.12\n",
    "# ! mamba activate wind_forecasting_env\n",
    "# ! conda install -c conda-forge jupyterlab mpi4py impi_rt\n",
    "# ! pip install ./OpenOA # have to change pyproject.toml to allow for python 3.12.7\n",
    "# ! pip install floris polars windrose netCDF4 statsmodels h5pyd seaborn pyarrow memory_profiler\n",
    "\n",
    "#%load_ext memory_profiler\n",
    "from data_loader import DataLoader\n",
    "from data_filter import DataFilter\n",
    "from data_inspector import DataInspector\n",
    "from openoa.utils import qa, plot, filters, power_curve, imputing\n",
    "import polars.selectors as cs\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sys import platform\n",
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print NetCDF Data Structure, Load Data, Transform Datetime Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False\n",
    "RELOAD_DATA = False\n",
    "\n",
    "if platform == \"darwin\":\n",
    "    DATA_DIR = \"/Users/ahenry/Documents/toolboxes/wind_forecasting/examples/data\"\n",
    "    # PL_SAVE_PATH = \"/Users/ahenry/Documents/toolboxes/wind_forecasting/examples/data/kp.turbine.zo2.b0.raw.parquet\"\n",
    "    # FILE_SIGNATURE = \"kp.turbine.z02.b0.*.*.*.nc\"\n",
    "    PL_SAVE_PATH = \"/Users/ahenry/Documents/toolboxes/wind_forecasting/examples/data/short_kp.turbine.zo2.b0.raw.parquet\"\n",
    "    FILE_SIGNATURE = \"kp.turbine.z02.b0.2022030*.*.*.nc\"\n",
    "    MULTIPROCESSOR = \"cf\"\n",
    "    TURBINE_INPUT_FILEPATH = \"/Users/ahenry/Documents/toolboxes/wind_forecasting/examples/inputs/ge_282_127.yaml\"\n",
    "    FARM_INPUT_FILEPATH = \"/Users/ahenry/Documents/toolboxes/wind_forecasting/examples/inputs/gch_KP_v4.yaml\"\n",
    "elif platform == \"linux\":\n",
    "    DATA_DIR = \"/pl/active/paolab/awaken_data/kp.turbine.z02.b0/\"\n",
    "    PL_SAVE_PATH = \"/scratch/alpine/aohe7145/awaken_data/kp.turbine.zo2.b0.raw.parquet\"\n",
    "    FILE_SIGNATURE = \"kp.turbine.z02.b0.*.*.*.nc\"\n",
    "    MULTIPROCESSOR = \"mpi\"\n",
    "    TURBINE_INPUT_FILEPATH = \"/projects/aohe7145/toolboxes/wind-forecasting/examples/inputs/ge_282_127.yaml\"\n",
    "    FARM_INPUT_FILEPATH = \"/projects/aohe7145/toolboxes/wind-forecasting/examples/inputs/gch_KP_v4.yaml\"\n",
    "\n",
    "DT = 5\n",
    "\n",
    "data_loader = DataLoader(data_dir=DATA_DIR, file_signature=FILE_SIGNATURE, multiprocessor=MULTIPROCESSOR, save_path=PL_SAVE_PATH, dt=DT,\n",
    "                         desired_feature_types=[\"time\", \"turbine_id\", \"turbine_status\", \"wind_direction\", \"wind_speed\", \"power_output\", \"nacelle_direction\"],\n",
    "                         ffill_limit=int(60 * 60 * 10 // DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 17:28:27,403 - INFO - NetCDF File: kp.turbine.z02.b0.20220301.000000.wt028.nc\n",
      "2024-10-16 17:28:27,404 - INFO - \n",
      "Global Attributes:\n",
      "2024-10-16 17:28:27,406 - INFO - \n",
      "Dimensions:\n",
      "2024-10-16 17:28:27,406 - INFO -   date: 244573\n",
      "2024-10-16 17:28:27,407 - INFO -   string7: 7\n",
      "2024-10-16 17:28:27,408 - INFO - \n",
      "Variables:\n",
      "2024-10-16 17:28:27,408 - INFO -   Flag:\n",
      "2024-10-16 17:28:27,410 - INFO -     Dimensions: ('date', 'string7')\n",
      "2024-10-16 17:28:27,413 - INFO -     Shape: (244573, 7)\n",
      "2024-10-16 17:28:27,426 - INFO -     Data type: |S1\n",
      "2024-10-16 17:28:27,429 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,434 - INFO -       _Encoding: utf-8\n",
      "2024-10-16 17:28:27,439 - INFO -   date:\n",
      "2024-10-16 17:28:27,440 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,466 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,476 - INFO -     Data type: int32\n",
      "2024-10-16 17:28:27,493 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,521 - INFO -       units: milliseconds since 2022-03-01 00:00:00.171000\n",
      "2024-10-16 17:28:27,539 - INFO -       calendar: proleptic_gregorian\n",
      "2024-10-16 17:28:27,541 - INFO -   WCNV.GnA1:\n",
      "2024-10-16 17:28:27,542 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,543 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,544 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,545 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,546 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,547 - INFO -   WCNV.GnA2:\n",
      "2024-10-16 17:28:27,552 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,553 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,554 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,555 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,557 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,559 - INFO -   WCNV.GnA3:\n",
      "2024-10-16 17:28:27,560 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,560 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,566 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,568 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,579 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,583 - INFO -   WCNV.GnPNV1:\n",
      "2024-10-16 17:28:27,600 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,606 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,608 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,612 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,615 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,618 - INFO -   WCNV.GnPNV2:\n",
      "2024-10-16 17:28:27,620 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,621 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,622 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,622 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,629 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,642 - INFO -   WCNV.GnPNV3:\n",
      "2024-10-16 17:28:27,661 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,664 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,667 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,669 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,672 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,675 - INFO -   WTUR.W:\n",
      "2024-10-16 17:28:27,675 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,678 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,678 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,682 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,688 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,690 - INFO -   WAVL.TurAvl:\n",
      "2024-10-16 17:28:27,692 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,693 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,693 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,694 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,696 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,699 - INFO -   WGEN.BrgDETmp:\n",
      "2024-10-16 17:28:27,700 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,702 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,703 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,706 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,707 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,708 - INFO -   WGEN.BrgNDETmp:\n",
      "2024-10-16 17:28:27,709 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,710 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,711 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,712 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,712 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,713 - INFO -   WGEN.InLetTmp:\n",
      "2024-10-16 17:28:27,713 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,714 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,715 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,715 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,716 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,717 - INFO -   WGEN.SttTmp1:\n",
      "2024-10-16 17:28:27,718 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,719 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,720 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,722 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,723 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,724 - INFO -   WGEN.SttTmp2:\n",
      "2024-10-16 17:28:27,725 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,726 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,726 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,727 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,727 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,727 - INFO -   WGEN.RotSpd:\n",
      "2024-10-16 17:28:27,728 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,728 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,728 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,729 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,730 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,731 - INFO -   WNAC.Dir:\n",
      "2024-10-16 17:28:27,731 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,732 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,733 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,733 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,733 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,733 - INFO -   WNAC.Tmp:\n",
      "2024-10-16 17:28:27,734 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,734 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,734 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,734 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,734 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,735 - INFO -   WMET.EnvTmp:\n",
      "2024-10-16 17:28:27,735 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,735 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,735 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,736 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,736 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,736 - INFO -   WROT.BlPthAngVal1:\n",
      "2024-10-16 17:28:27,737 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,737 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,738 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,738 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,738 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,738 - INFO -   WROT.BlPthAngVal2:\n",
      "2024-10-16 17:28:27,739 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,739 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,739 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,740 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,740 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,740 - INFO -   WROT.BlPthAngVal3:\n",
      "2024-10-16 17:28:27,741 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,741 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,741 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,742 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,742 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,743 - INFO -   WROT.RotSpd:\n",
      "2024-10-16 17:28:27,743 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,744 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,744 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,744 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,746 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,747 - INFO -   WTUR.TurSt:\n",
      "2024-10-16 17:28:27,747 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,747 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,748 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,748 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,749 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,750 - INFO -   WMET.HorWdDir:\n",
      "2024-10-16 17:28:27,750 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,750 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,750 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,751 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,753 - INFO -       _FillValue: nan\n",
      "2024-10-16 17:28:27,753 - INFO -   WMET.HorWdSpd:\n",
      "2024-10-16 17:28:27,754 - INFO -     Dimensions: ('date',)\n",
      "2024-10-16 17:28:27,755 - INFO -     Shape: (244573,)\n",
      "2024-10-16 17:28:27,755 - INFO -     Data type: float64\n",
      "2024-10-16 17:28:27,756 - INFO -     Attributes:\n",
      "2024-10-16 17:28:27,757 - INFO -       _FillValue: nan\n"
     ]
    }
   ],
   "source": [
    "data_loader.print_netcdf_structure(data_loader.file_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not RELOAD_DATA and os.path.exists(data_loader.save_path):\n",
    "    # Note that the order of the columns in the provided schema must match the order of the columns in the CSV being read.\n",
    "    \n",
    "    schema = pl.Schema({**{\"time\": pl.Datetime(time_unit=\"ms\")},\n",
    "                        **{\n",
    "                            f\"{feat}_{tid}\": pl.Float64\n",
    "                            for feat in [\"turbine_status\", \"wind_direction\", \"wind_speed\", \"power_output\", \"nacelle_direction\"] \n",
    "                            for tid in [f\"wt{d+1:03d}\" for d in range(88)]}\n",
    "                        })\n",
    "    \n",
    "    df_query = pl.scan_parquet(source=data_loader.save_path, hive_schema=schema)\n",
    "    data_loader.available_features = sorted(df_query.collect_schema().names())\n",
    "    data_loader.turbine_ids = sorted(np.unique([re.findall(f\"(?<=wind_direction_)(.*)\", feat)[0] for feat in data_loader.available_features if \"wind_direction\" in feat]))\n",
    "else:\n",
    "    df_query = data_loader.read_multi_netcdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Wind Farm, Data Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inspector = DataInspector(turbine_input_filepath=TURBINE_INPUT_FILEPATH, farm_input_filepath=FARM_INPUT_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT and False:\n",
    "    data_inspector.plot_wind_farm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    data_inspector.plot_wind_speed_power(df_query, turbine_ids=[\"wt073\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    data_inspector.plot_wind_speed_weibull(df_query, turbine_ids=[\"wt073\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    data_inspector.plot_wind_rose(df_query, turbine_ids=[\"wt073\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    data_inspector.plot_correlation(df_query, \n",
    "    DataInspector.get_features(df_query, feature_types=[\"wind_speed\", \"wind_direction\", \"nacelle_direction\"], turbine_ids=[\"wt073\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    data_inspector.plot_boxplot_wind_speed_direction(df_query, turbine_ids=[\"wt073\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    data_inspector.plot_time_series(df_query, turbine_ids=[\"wt073\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import timedelta\n",
    "# idx = np.where(df_query.select(pl.col(\"time\")).collect(streaming=True).to_series().diff().to_numpy() != np.timedelta64(5, 's'))[0]\n",
    "# idx\n",
    "\n",
    "# df_query.select(pl.col(\"time\")).filter(pl.col(\"time\").diff() != np.timedelta64(5, 's')).collect(streaming=True)\n",
    "# df_query.select(\"time\", \"wind_direction_wt073\").filter(pl.col(\"wind_direction_wt073\").is_null()).collect(streaming=True)\n",
    "# df_query.select(\"time\", \"power_output_wt073\").filter(pl.col(\"power_output_wt073\").is_null()).collect(streaming=True)\n",
    "# from datetime import datetime\n",
    "# df_query.select(\"time\", \"wind_direction_wt073\").filter((pl.col(\"time\") >= datetime.strptime(\"2022-03-09 00:00:00\", '%Y-%m-%d %H:%M:%S')) \n",
    "#                                                     & (pl.col(\"time\") <= datetime.strptime(\"2022-03-17 00:00:00\", '%Y-%m-%d %H:%M:%S'))).collect(streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenOA Data Preparation & Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_cols = DataInspector.get_features(df_query, \"wind_speed\")\n",
    "wd_cols = DataInspector.get_features(df_query, \"wind_direction\")\n",
    "pwr_cols = DataInspector.get_features(df_query, \"power_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features of interest = ['time', 'turbine_id', 'turbine_status', 'wind_direction', 'wind_speed', 'power_output', 'nacelle_direction']\n",
      "Available features = ['nacelle_direction_wt028', 'nacelle_direction_wt033', 'nacelle_direction_wt073', 'power_output_wt028', 'power_output_wt033', 'power_output_wt073', 'time', 'turbine_status_wt028', 'turbine_status_wt033', 'turbine_status_wt073', 'wind_direction_wt028', 'wind_direction_wt033', 'wind_direction_wt073', 'wind_speed_wt028', 'wind_speed_wt033', 'wind_speed_wt073']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features of interest = {data_loader.desired_feature_types}\")\n",
    "print(f\"Available features = {data_loader.available_features}\")\n",
    "# qa.describe(DataInspector.collect_data(df=df_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plot.column_histograms(DataInspector.collect_data(df=df_query, \n",
    "    feature_types=DataInspector.get_features(df_query, [\"wind_speed\", \"wind_direction\", \"power_output\", \"nacelle_direction\"], [\"wt073\", \"wt028\", \"wt033\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filter = DataFilter(turbine_availability_col=None, turbine_status_col=\"turbine_status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Inoperational Turbine Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature wind_speed_wt028 has 70.7668427645553 % unfiltered values.\n",
      "Feature wind_speed_wt033 has 67.90139425957193 % unfiltered values.\n",
      "Feature wind_speed_wt073 has 60.64076030717281 % unfiltered values.\n",
      "Feature power_output_wt028 has 70.7668427645553 % unfiltered values.\n",
      "Feature power_output_wt033 has 67.90139425957193 % unfiltered values.\n",
      "Feature power_output_wt073 has 60.64076030717281 % unfiltered values.\n"
     ]
    }
   ],
   "source": [
    "# check if wind speed/dir measurements from inoperational turbines differ from fully operational \n",
    "# df_query = data_filter.filter_inoperational(df_query, status_codes=[1], include_nan=False)\n",
    "status_codes = [1]\n",
    "mask = lambda tid: pl.col(f\"turbine_status_{tid}\").is_in(status_codes) | pl.col(f\"turbine_status_{tid}\").is_null()\n",
    "features = ws_cols + pwr_cols\n",
    "DataInspector.print_pc_unfiltered_vals(df_query, features, mask)\n",
    "\n",
    "if PLOT:\n",
    "    data_inspector.plot_filtered_vs_unfiltered(df_query, mask, ws_cols + wd_cols, [\"wind_speed\", \"wind_direction\"], [\"Wind Speed [m/s]\", \"Wind Direction [deg]\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "power_output_wt073    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query.select(f\"power_output_wt073\").collect(streaming=True).to_pandas().isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS Score for feature wind_speed_wt028 = 0.02328274567179356\n",
      "JS Score for feature wind_speed_wt033 = 0.03544794843578207\n",
      "JS Score for feature wind_speed_wt073 = 0.03692474764361267\n",
      "JS Score for feature wind_direction_wt028 = 0.01216459200845605\n",
      "JS Score for feature wind_direction_wt033 = 0.01136192489625543\n",
      "JS Score for feature wind_direction_wt073 = 0.016380549342631497\n"
     ]
    }
   ],
   "source": [
    "# loop through each turbine's wind speed and wind direction columns, and compare the distribution of data with and without the inoperational turbines\n",
    "# fill out_of_range measurements with Null st they are marked for interpolation via impute or linear/forward fill interpolation later\n",
    "threshold = 0.01\n",
    "df_query = data_filter.conditional_filter(df_query, threshold, mask, ws_cols + wd_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind Speed Range Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature wind_speed_wt028 has 100.0 % unfiltered values.\n",
      "Feature wind_speed_wt033 has 100.0 % unfiltered values.\n",
      "Feature wind_speed_wt073 has 100.0 % unfiltered values.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check for wind speed values that are outside of the acceptable range\n",
    "ws = DataInspector.collect_data(df=df_query, feature_types=\"wind_speed\")\n",
    "out_of_range = (filters.range_flag(ws, lower=0, upper=70) & ~ws.isna()).values # range flag includes formerly null values as nan\n",
    "del ws\n",
    "# qa.describe(DataInspector.collect_data(df=df_query, feature_types=\"wind_speed\", mask=np.any(out_of_range, axis=1)))\n",
    "\n",
    "# check if wind speed/dir measurements from inoperational turbines differ from fully operational \n",
    "mask = lambda tid: ~out_of_range[:, data_loader.turbine_ids.index(tid)]\n",
    "features = ws_cols\n",
    "DataInspector.print_pc_unfiltered_vals(df_query, features, mask)\n",
    "\n",
    "if PLOT:\n",
    "    data_inspector.plot_filtered_vs_unfiltered(df_query, mask, ws_cols, [\"wind_speed\"], [\"Wind Speed [m/s]\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "power_output_wt073    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_range\n",
    "df_query.select(f\"power_output_wt073\").collect(streaming=True).to_pandas().isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS Score for feature wind_speed_wt028 = 0.0\n",
      "JS Score for feature wind_speed_wt033 = 0.0\n",
      "JS Score for feature wind_speed_wt073 = 0.0\n"
     ]
    }
   ],
   "source": [
    "# loop through each turbine's wind speed and wind direction columns, and compare the distribution of data with and without the inoperational turbines\n",
    "# fill out_of_range measurements with Null st they are marked for interpolation via impute or linear/forward fill interpolation later\n",
    "threshold = 0.01\n",
    "df_query = data_filter.conditional_filter(df_query, threshold, mask, ws_cols)\n",
    "# df_query = df_query.with_columns(\n",
    "#                 [pl.when(~out_of_range[:, data_loader.turbine_ids.index(feat.split(\"_\")[-1])]).then(pl.col(feat)).alias(feat)\n",
    "#                 for feat in ws_cols]\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del out_of_range "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Curve Window Range Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature wind_speed_wt028 has 98.46890147595447 % unfiltered values.\n",
      "Feature wind_speed_wt033 has 99.0700397581831 % unfiltered values.\n",
      "Feature wind_speed_wt073 has 99.15377702739502 % unfiltered values.\n",
      "Feature power_output_wt028 has 98.46890147595447 % unfiltered values.\n",
      "Feature power_output_wt033 has 99.0700397581831 % unfiltered values.\n",
      "Feature power_output_wt073 has 99.15377702739502 % unfiltered values.\n"
     ]
    }
   ],
   "source": [
    "# apply a window range filter to remove data with power values outside of the window from 20 to 3000 kW for wind speeds between 5 and 40 m/s.\n",
    "# identifies when turbine is shut down, filtering for normal turbine operation\n",
    "\n",
    "out_of_window = np.stack([(filters.window_range_flag(window_col=DataInspector.collect_data(df=df_query, \n",
    "                                                                                    feature_types=[\"wind_speed\"], \n",
    "                                                                                    turbine_ids=[tid])[f\"wind_speed_{tid}\"],\n",
    "                                                    window_start=5., window_end=40., \n",
    "                                                    value_col=DataInspector.collect_data(df=df_query, \n",
    "                                                                                    feature_types=[\"power_output\"], \n",
    "                                                                                    turbine_ids=[tid])[f\"power_output_{tid}\"],\n",
    "                                                    value_min=20., value_max=3000.)\n",
    "                        & df_query.select(no_nulls=pl.all_horizontal(pl.col(f\"wind_speed_{tid}\").is_not_null(), pl.col(f\"power_output_{tid}\").is_not_null()))\\\n",
    "                                  .collect(streaming=True).to_pandas()[\"no_nulls\"]\n",
    "                                #   & ~DataInspector.collect_data(df=df_query, feature_types=\"wind_speed\", turbine_ids=tid).isna()\n",
    "                                #   & ~DataInspector.collect_data(df=df_query, feature_types=\"power_output\", turbine_ids=tid).isna()\n",
    "                                  ).values for tid in data_loader.turbine_ids], axis=1)\n",
    "\n",
    "\n",
    "# check if wind speed/dir measurements from inoperational turbines differ from fully operational \n",
    "mask = lambda tid: ~out_of_window[:, data_loader.turbine_ids.index(tid)]\n",
    "features = ws_cols + pwr_cols\n",
    "DataInspector.print_pc_unfiltered_vals(df_query, features, mask)\n",
    "\n",
    "if PLOT:\n",
    "    data_inspector.plot_filtered_vs_unfiltered(df_query, mask, features, [\"wind_speed\", \"power_output\"], [\"Wind Speed [m/s]\", \"Power Output [W]\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "power_output_wt033    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query.select(f\"power_output_wt033\").collect(streaming=True).to_pandas().isna().sum() \n",
    "# DataInspector.collect_data(df_query, feature_types=[\"time\", \"wind_speed\", \"power_output\"], turbine_ids=[\"wt073\"], mask=out_of_window[:, 2])\n",
    "# out_of_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if PLOT:\n",
    "    # plot values that are outside of power-wind speed range\n",
    "    plot.plot_power_curve(\n",
    "        DataInspector.collect_data(df=df_query, feature_types=\"wind_speed\"),\n",
    "        DataInspector.collect_data(df=df_query, feature_types=\"power_output\"),\n",
    "        flag=out_of_window,\n",
    "        flag_labels=(\"Outside Acceptable Window\", \"Acceptable Power Curve Points\"),\n",
    "        xlim=(-1, 15),\n",
    "        ylim=(-100, 3000),\n",
    "        legend=True,\n",
    "        scatter_kwargs=dict(alpha=0.4, s=10)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS Score for feature wind_speed_wt028 = 3.541032279560565e-05\n",
      "JS Score for feature wind_speed_wt033 = 3.395173905720496e-05\n",
      "JS Score for feature wind_speed_wt073 = 3.1294921719538925e-05\n",
      "JS Score for feature power_output_wt028 = 5.8033281632504865e-05\n",
      "JS Score for feature power_output_wt033 = 1.813105959433226e-05\n",
      "JS Score for feature power_output_wt073 = 1.7307610666359482e-05\n"
     ]
    }
   ],
   "source": [
    "# fill cells corresponding to values that are outside of power-wind speed window range with Null st they are marked for interpolation via impute or linear/forward fill interpolation later\n",
    "# loop through each turbine's wind speed and wind direction columns, and compare the distribution of data with and without the inoperational turbines\n",
    "threshold = 0.01\n",
    "df_query = data_filter.conditional_filter(df_query, threshold, mask, features)\n",
    "\n",
    "# df_query = df_query.with_columns(\n",
    "#                 [pl.when(~out_of_window[:, data_loader.turbine_ids.index(feat.split(\"_\")[-1])]).then(pl.col(feat)).alias(feat)\n",
    "#                 for feat in ws_cols + pwr_cols]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del out_of_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_query.collect(streaming=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Curve Bin Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature wind_speed_wt028 has 99.98774576548118 % unfiltered values.\n",
      "Feature wind_speed_wt033 has 99.98502260225479 % unfiltered values.\n",
      "Feature wind_speed_wt073 has 99.98910734709439 % unfiltered values.\n",
      "Feature power_output_wt028 has 99.98774576548118 % unfiltered values.\n",
      "Feature power_output_wt033 has 99.98502260225479 % unfiltered values.\n",
      "Feature power_output_wt073 has 99.98910734709439 % unfiltered values.\n"
     ]
    }
   ],
   "source": [
    "# apply a bin filter to remove data with power values outside of an envelope around median power curve at each wind speed\n",
    "\n",
    "bin_outliers = np.stack([(filters.bin_filter(\n",
    "                                  bin_col=f\"power_output_{tid}\", \n",
    "                                  value_col=f\"wind_speed_{tid}\", \n",
    "                                  bin_width=50, threshold=3,\n",
    "                                  center_type=\"median\", \n",
    "                                  bin_min=20., bin_max=0.90*(df_query.select(f\"power_output_{tid}\").max().collect(streaming=True).item() or 3000.),\n",
    "                                  threshold_type=\"scalar\", direction=\"below\",\n",
    "                                  data=DataInspector.collect_data(df=df_query, \n",
    "                                                                  feature_types=[\"wind_speed\", \"power_output\"], \n",
    "                                                                  turbine_ids=[tid])\n",
    "                                  )\n",
    "                                & df_query.select(no_nulls=pl.all_horizontal(pl.col(f\"wind_speed_{tid}\").is_not_null(), pl.col(f\"power_output_{tid}\").is_not_null()))\\\n",
    "                                  .collect(streaming=True).to_pandas()[\"no_nulls\"]\n",
    "                                #   & ~DataInspector.collect_data(df=df_query, feature_types=\"wind_speed\", turbine_ids=tid).isna()\n",
    "                                #   & ~DataInspector.collect_data(df=df_query, feature_types=\"power_output\", turbine_ids=tid).isna()\n",
    "                                  ).values for tid in data_loader.turbine_ids], axis=1)\n",
    "# qa.describe(DataInspector.collect_data(df=df_query, feature_types=[\"wind_speed\", \"power_output\"], mask=bin_outliers))\n",
    "\n",
    "# check if wind speed/dir measurements from inoperational turbines differ from fully operational \n",
    "mask = lambda tid: ~bin_outliers[:, data_loader.turbine_ids.index(tid)]\n",
    "\n",
    "features = ws_cols + pwr_cols\n",
    "DataInspector.print_pc_unfiltered_vals(df_query, features, mask)\n",
    "\n",
    "if PLOT:\n",
    "    data_inspector.plot_filtered_vs_unfiltered(df_query, mask, features, [\"wind_speed\", \"power_output\"], [\"Wind Speed [m/s]\", \"Power Output [W]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       ...,\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    # plot values outside the power-wind speed bin filter\n",
    "    plot.plot_power_curve(\n",
    "        DataInspector.collect_data(df=df_query, feature_types=\"wind_speed\"),\n",
    "        DataInspector.collect_data(df=df_query, feature_types=\"power_output\"),\n",
    "        flag=bin_outliers,\n",
    "        flag_labels=(\"Anomylous Data\", \"Normal Wind Speed Sensor Operation\"),\n",
    "        xlim=(-1, 15),\n",
    "        ylim=(-100, 3000),\n",
    "        legend=True,\n",
    "        scatter_kwargs=dict(alpha=0.4, s=10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS Score for feature wind_speed_wt028 = 1.9029505489944738e-08\n",
      "JS Score for feature wind_speed_wt033 = 1.8675457807432357e-08\n",
      "JS Score for feature wind_speed_wt073 = 2.747139979315346e-08\n",
      "JS Score for feature power_output_wt028 = 5.220738859187891e-08\n",
      "JS Score for feature power_output_wt033 = 5.837710383649833e-08\n",
      "JS Score for feature power_output_wt073 = 4.389664599272941e-08\n"
     ]
    }
   ],
   "source": [
    "# fill cells corresponding to values that are outside of power-wind speed bins with Null st they are marked for interpolation via impute or linear/forward fill interpolation later\n",
    "# loop through each turbine's wind speed and wind direction columns, and compare the distribution of data with and without the inoperational turbines\n",
    "threshold = 0.01\n",
    "df_query = data_filter.conditional_filter(df_query, threshold, mask, features)\n",
    "# df_query = df_query.with_columns(\n",
    "#                 [pl.when(~bin_outliers[:, data_loader.turbine_ids.index(feat.split(\"_\")[-1])]).then(pl.col(feat)).alias(feat)\n",
    "#                 for feat in ws_cols + pwr_cols]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Curve Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    # Fit the power curves\n",
    "    iec_curve = power_curve.IEC(\n",
    "        windspeed_col=\"wind_speed\", power_col=\"power_output\",\n",
    "        data=DataInspector.unpivot_dataframe(df_query).select(\"wind_speed\", \"power_output\").filter(pl.all_horizontal(pl.all().is_not_null())).collect(streaming=True).to_pandas(),\n",
    "        )\n",
    "\n",
    "    l5p_curve = power_curve.logistic_5_parametric(\n",
    "        windspeed_col=\"wind_speed\", power_col=\"power_output\",\n",
    "        data=DataInspector.unpivot_dataframe(df_query).select(\"wind_speed\", \"power_output\").filter(pl.all_horizontal(pl.all().is_not_null())).collect(streaming=True).to_pandas(),\n",
    "        )\n",
    "\n",
    "    spline_curve = power_curve.gam(\n",
    "        windspeed_col=\"wind_speed\", power_col=\"power_output\",\n",
    "        data=DataInspector.unpivot_dataframe(df_query).select(\"wind_speed\", \"power_output\").filter(pl.all_horizontal(pl.all().is_not_null())).collect(streaming=True).to_pandas(), \n",
    "        n_splines=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    fig, ax = plot.plot_power_curve(\n",
    "        DataInspector.collect_data(df=df_query, feature_types=\"wind_speed\"),\n",
    "        DataInspector.collect_data(df=df_query, feature_types=\"power_output\"),\n",
    "        flag=np.zeros(DataInspector.collect_data(df=df_query, feature_types=\"wind_speed\").shape, dtype=bool),\n",
    "        flag_labels=(\"\", \"Filtered Power Curve\"),\n",
    "        xlim=(-1, 15),  # optional input for refining plots\n",
    "        ylim=(-100, 3000),  # optional input for refining plots\n",
    "        legend=False,  # optional flag for adding a legend\n",
    "        scatter_kwargs=dict(alpha=0.4, s=10),  # optional input for refining plots\n",
    "        return_fig=True,\n",
    "    )\n",
    "\n",
    "    x = np.linspace(0, 20, 100)\n",
    "    ax.plot(x, iec_curve(x), color=\"red\", label = \"IEC\", linewidth = 3)\n",
    "    ax.plot(x, spline_curve(x), color=\"C1\", label = \"Spline\", linewidth = 3)\n",
    "    ax.plot(x, l5p_curve(x), color=\"C2\", label = \"L5P\", linewidth = 3)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unresponsive Sensor Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find stuck sensor measurements for each turbine and set them to null\n",
    "# TODO question does unresponsive flag include nan values\n",
    "# frozen_thresholds = [(data_loader.ffill_limit * i) + 1 for i in range(1, 19)]\n",
    "# print(frozen_thresholds)\n",
    "# ws_pcs = []\n",
    "# wd_pcs = []\n",
    "# pwr_pcs = []\n",
    "# for thr in frozen_thresholds:\n",
    "#     ws_frozen_sensor = filters.unresponsive_flag(data=DataInspector.collect_data(df=df_query, feature_types=\"wind_speed\"), threshold=thr).values\n",
    "#     wd_frozen_sensor = filters.unresponsive_flag(data=DataInspector.collect_data(df=df_query, feature_types=\"wind_direction\"), threshold=thr).values\n",
    "#     pwr_frozen_sensor = filters.unresponsive_flag(data=DataInspector.collect_data(df=df_query, feature_types=\"power_output\"), threshold=thr).values\n",
    "\n",
    "#     # check if wind speed/dir measurements from inoperational turbines differ from fully operational\n",
    "#     print(f\"For a threshold of {thr} for the frozen sensor filters:\")\n",
    "#     ws_pcs.append(DataInspector.print_pc_unfiltered_vals(df_query, ws_cols, lambda tid: ws_frozen_sensor[:, data_loader.turbine_ids.index(tid)]))\n",
    "#     wd_pcs.append(DataInspector.print_pc_unfiltered_vals(df_query, wd_cols, lambda tid: wd_frozen_sensor[:, data_loader.turbine_ids.index(tid)]))\n",
    "#     pwr_pcs.append(DataInspector.print_pc_unfiltered_vals(df_query, pwr_cols, lambda tid: pwr_frozen_sensor[:, data_loader.turbine_ids.index(tid)]))\n",
    "\n",
    "# fig, ax = plt.subplots(3, 1, sharex=True)\n",
    "# for t_idx in range(len(data_loader.turbine_ids)):\n",
    "#     ax[0].scatter(x=frozen_thresholds, y=[x[1][t_idx] for x in ws_pcs], label=data_loader.turbine_ids[t_idx])\n",
    "#     ax[1].scatter(x=frozen_thresholds, y=[x[1][t_idx] for x in wd_pcs], label=data_loader.turbine_ids[t_idx])\n",
    "#     ax[2].scatter(x=frozen_thresholds, y=[x[1][t_idx] for x in pwr_pcs],label=data_loader.turbine_ids[t_idx])\n",
    "\n",
    "# h, l = ax[0].get_legend_handles_labels()\n",
    "# ax[0].legend(h[:len(data_loader.turbine_ids)], l[:len(data_loader.turbine_ids)])\n",
    "# ax[0].set_title(\"Percentage of Unfrozen Wind Speed Measurements\")\n",
    "# ax[1].set_title(\"Percentage of Unfrozen Wind Direction Measurements\")\n",
    "# ax[2].set_title(\"Percentage of Unfrozen Power Output Measurements\")\n",
    "# qa.describe(pl.concat([DataInspector.collect_data(df=df_query, feature_types=feature_type, mask=mask, to_pandas=False)\n",
    "#                         for mask, feature_type in zip([ws_frozen_sensor, wd_frozen_sensor, pwr_frozen_sensor], [\"wind_speed\", \"wind_direction\", \"power_output\"])], \n",
    "#                             how=\"horizontal\")\\\n",
    "#                                .to_pandas())\n",
    "\n",
    "# TODO\n",
    "if False:\n",
    "    thr = data_loader.ffill_limit + 1\n",
    "    # frozen_sensor = (filters.unresponsive_flag(data=df_query.select(features).collect(streaming=True).to_pandas(), threshold=thr)\n",
    "                                    # & df_query.select([pl.col(feat).is_not_null().alias(feat) for feat in features])\\\n",
    "                                    #   .collect(streaming=True).to_pandas()\n",
    "                                    #   ).values\n",
    "    features = ws_cols + wd_cols + pwr_cols\n",
    "    frozen_sensor = np.stack([(filters.unresponsive_flag(data=df_query.select(feat).collect(streaming=True).to_pandas(), threshold=thr)\n",
    "                                    & df_query.select(pl.col(feat).is_not_null().alias(feat))\\\n",
    "                                    .collect(streaming=True).to_pandas()\n",
    "                                    ).values for feat in features], axis=1)\n",
    "    mask = lambda tid: ~frozen_sensor[:, data_loader.turbine_ids.index(tid)]\n",
    "\n",
    "# df_query.select([pl.col(feat).is_not_null().name.suffix(\"_not_null\") for feat in ws_cols])\\\n",
    "#                                   .collect(streaming=True).to_pandas()\n",
    "# \n",
    "# ws_frozen_sensor = (filters.unresponsive_flag(data=DataInspector.collect_data(df=df_query, feature_types=\"wind_speed\"), threshold=thr)\n",
    "#                                 & df_query.select([pl.col(feat).is_not_null().name.suffix(\"_not_null\") for feat in ws_cols])\\\n",
    "#                                   .collect(streaming=True).to_pandas()\n",
    "#                                   ).values\n",
    "# ws_frozen_sensor\n",
    "# wd_frozen_sensor = np.stack([(filters.unresponsive_flag(data=DataInspector.collect_data(df=df_query, feature_types=\"wind_direction\"), threshold=thr)\n",
    "#                                 & df_query.select(no_nulls=pl.col(f\"wind_speed_{tid}\").is_not_null())\\\n",
    "#                                   .collect(streaming=True).to_pandas()[\"no_nulls\"]\n",
    "#                                   ).values for tid in data_loader.turbine_ids], axis=1)\n",
    "# pwr_frozen_sensor = np.stack([(filters.unresponsive_flag(data=DataInspector.collect_data(df=df_query, feature_types=\"power_output\"), threshold=thr)\n",
    "#                                 & df_query.select(no_nulls=pl.col(f\"wind_speed_{tid}\").is_not_null())\\\n",
    "#                                   .collect(streaming=True).to_pandas()[\"no_nulls\"]\n",
    "#                                   ).values for tid in data_loader.turbine_ids], axis=1)\n",
    "\n",
    "# wd_frozen_sensor = filters.unresponsive_flag(data=DataInspector.collect_data(df=df_query, feature_types=\"wind_direction\"), threshold=thr).values\n",
    "# pwr_frozen_sensor = filters.unresponsive_flag(data=DataInspector.collect_data(df=df_query, feature_types=\"power_output\"), threshold=thr).values\n",
    "\n",
    "# ws_mask = lambda tid: ~ws_frozen_sensor[:, data_loader.turbine_ids.index(tid)]\n",
    "# wd_mask = lambda tid: ~wd_frozen_sensor[:, data_loader.turbine_ids.index(tid)]\n",
    "# pwr_mask = lambda tid: ~pwr_frozen_sensor[:, data_loader.turbine_ids.index(tid)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    frozen_sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plot.plot_power_curve(\n",
    "        DataInspector.collect_data(df=df_query, feature_types=\"wind_speed\"),\n",
    "        DataInspector.collect_data(df=df_query, feature_types=\"power_output\"),\n",
    "        flag=ws_frozen_sensor,\n",
    "        flag_labels=(f\"Wind Speed Unresponsive Sensors (n={ws_frozen_sensor.sum():,.0f})\", \"Normal Turbine Operations\"),\n",
    "        xlim=(-1, 15),  # optional input for refining plots\n",
    "        ylim=(-100, 3000),  # optional input for refining plots\n",
    "        legend=True,  # optional flag for adding a legend\n",
    "        scatter_kwargs=dict(alpha=0.4, s=10)  # optional input for refining plots\n",
    "    )\n",
    "\n",
    "    plot.plot_power_curve(\n",
    "        DataInspector.collect_data(df=df_query, feature_types=\"wind_speed\"),\n",
    "        DataInspector.collect_data(df=df_query, feature_types=\"power_output\"),\n",
    "        flag=wd_frozen_sensor,\n",
    "        flag_labels=(f\"Wind Direction Unresponsive Sensors (n={wd_frozen_sensor.sum():,.0f})\", \"Normal Turbine Operations\"),\n",
    "        xlim=(-1, 15),  # optional input for refining plots\n",
    "        ylim=(-100, 3000),  # optional input for refining plots\n",
    "        legend=True,  # optional flag for adding a legend\n",
    "        scatter_kwargs=dict(alpha=0.4, s=10)  # optional input for refining plots\n",
    "    )\n",
    "\n",
    "    plot.plot_power_curve(\n",
    "        DataInspector.collect_data(df=df_query, feature_types=\"wind_speed\"),\n",
    "        DataInspector.collect_data(df=df_query, feature_types=\"power_output\"),\n",
    "        flag=pwr_frozen_sensor,\n",
    "        flag_labels=(f\"Power Output Unresponsive Sensors (n={pwr_frozen_sensor.sum():,.0f})\", \"Normal Turbine Operations\"),\n",
    "        xlim=(-1, 15),  # optional input for refining plots\n",
    "        ylim=(-100, 3000),  # optional input for refining plots\n",
    "        legend=True,  # optional flag for adding a legend\n",
    "        scatter_kwargs=dict(alpha=0.4, s=10)  # optional input for refining plots\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the values corresponding to frozen sensor measurements to null or interpolate (instead of dropping full row, since other sensors could be functioning properly)\n",
    "# fill stuck sensor measurements with Null st they are marked for interpolation later,\n",
    "if False:\n",
    "    threshold = 0.01\n",
    "    df_query = data_filter.conditional_filter(df_query, threshold, mask, features)\n",
    "# df_query = df_query.with_columns(\n",
    "#                 [pl.when(~frozen_mask[:, data_loader.turbine_ids.index(feat.split(\"_\")[-1])]).then(pl.col(feat)).alias(feat)\n",
    "#                 for features, frozen_mask in zip(\n",
    "#                     [ws_cols, wd_cols, pwr_cols], \n",
    "#                     [ws_frozen_sensor, wd_frozen_sensor, pwr_frozen_sensor])\n",
    "#                 for feat in features]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    del frozen_sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess and Impute Turbine Missing Data from Correlated Measurements OR Split Dataset during Time Stamps for which many Turbines have Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "must specify `on` OR `left_on` and `right_on`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[194], line 52\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# # If no group is matched, assign a default value (e.g., -1)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m group_number \u001b[38;5;241m=\u001b[39m group_number\u001b[38;5;241m.\u001b[39motherwise(pl\u001b[38;5;241m.\u001b[39mlit(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     47\u001b[0m \u001b[43mdf_query_is_missing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup_number\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmissing_group\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmissing_group\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_by\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmissing_group\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mends_with\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_missing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmissing_group\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m---> 52\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_query_missing_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\\\n\u001b[1;32m     53\u001b[0m          \u001b[38;5;241m.\u001b[39mcollect(streaming\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;66;03m#  \u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# TODO plot number of missing wind dir/wind speed data for each wind turbine (missing duration on x axis, turbine id on y axis, color for wind direction/wind speed)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# # sns.scatterplot(x=df.filter(pl.col(\"wind_speed\").is_null()).select(\"time\").to_numpy().flatten(), y=df.filter(pl.col(\"wind_speed\").is_null()).select(\"turbine_id\").to_numpy().flatten())\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# ax.legend()\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wind_forecasting_env/lib/python3.12/site-packages/polars/lazyframe/frame.py:4608\u001b[0m, in \u001b[0;36mLazyFrame.join\u001b[0;34m(self, other, on, how, left_on, right_on, suffix, validate, join_nulls, coalesce, allow_parallel, force_parallel)\u001b[0m\n\u001b[1;32m   4606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4607\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust specify `on` OR `left_on` and `right_on`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 4608\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   4610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_pyldf(\n\u001b[1;32m   4611\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ldf\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   4612\u001b[0m         other\u001b[38;5;241m.\u001b[39m_ldf,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4622\u001b[0m     )\n\u001b[1;32m   4623\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: must specify `on` OR `left_on` and `right_on`"
     ]
    }
   ],
   "source": [
    "# if there is a short or long gap for some turbines, impute them using the imputing.impute_all_assets_by_correlation function\n",
    "#       else if there is a short or long gap for many turbines, split the dataset\n",
    "missing_col_thr = 2\n",
    "missing_timesteps_thr = int(10 * 60 * 60 // data_loader.dt)\n",
    "missing_data_cols = [\"wind_speed\", \"wind_direction\"]\n",
    "\n",
    "# check for any periods of time for which more than 'missing_col_thr' features have missing data\n",
    "#.with_columns(num_nulls=pl.sum_horizontal(cs.numeric().is_null()))\\\n",
    "df_query_is_missing = df_query.select([\"time\"] + [cs.starts_with(col) for col in missing_data_cols])\\\n",
    "        .with_columns(cs.numeric().is_null().name.suffix(\"_is_missing\"))\\\n",
    "        .select(\"time\", cs.ends_with(\"is_missing\"))\\\n",
    "        .with_columns(**{f\"{col}_num_missing\": pl.sum_horizontal(cs.starts_with(col) & cs.ends_with(\"is_missing\")) for col in missing_data_cols})\\\n",
    "        .filter(pl.sum_horizontal(cs.ends_with(\"num_missing\")) > missing_col_thr)\\\n",
    "        .with_columns(dt=pl.col(\"time\").diff())\\\n",
    "        .select(\"time\", \"dt\", cs.ends_with(\"num_missing\"), cs.ends_with(\"is_missing\"))\\\n",
    "        .with_columns(continuous=pl.col(\"dt\")==np.timedelta64(data_loader.dt, \"s\"))\\\n",
    "        .with_columns(continuous_shifted=pl.col(\"continuous\").shift(-1))\n",
    "\n",
    "df_query_missing_times = df_query_is_missing.select(missing_start_time=pl.when(\n",
    "                                      (pl.col(\"continuous\") | pl.col(\"continuous\").is_null()) & ~pl.col(\"continuous_shifted\") )\\\n",
    "                                        .then(pl.col(\"time\")),\n",
    "                            missing_end_time=pl.when(\n",
    "                                      ~pl.col(\"continuous\") & (pl.col(\"continuous_shifted\") | pl.col(\"continuous_shifted\").is_null()))\\\n",
    "                                        .then(pl.col(\"time\")).shift(-1),\n",
    "                              )\\\n",
    "                    .filter(pl.any_horizontal(pl.col(\"missing_start_time\").is_not_null(), pl.col(\"missing_end_time\").is_not_null()))\\\n",
    "                    .with_columns(missing_duration=pl.col(\"missing_end_time\") - pl.col(\"missing_start_time\"))\\\n",
    "                    .drop_nulls()\n",
    "# df_query_missing_times.collect()\n",
    "\n",
    "\n",
    "# Create the condition for the group\n",
    "group_number = None\n",
    "\n",
    "# Create conditions to assign group numbers based on time ranges\n",
    "for i, (start, end) in enumerate(df_query_missing_times.select(\"missing_start_time\", \"missing_end_time\").collect(streaming=True).iter_rows()):\n",
    "    # print(i, start, end, duration)\n",
    "    time_cond = pl.col(\"time\").is_between(start, end)\n",
    "    if group_number is None:\n",
    "        group_number = pl.when(time_cond).then(pl.lit(i))\n",
    "    else:\n",
    "        group_number = group_number.when(time_cond).then(pl.lit(i))\n",
    "  \n",
    "# # If no group is matched, assign a default value (e.g., -1)\n",
    "group_number = group_number.otherwise(pl.lit(-1))\n",
    "\n",
    "pl.concat([df_query_is_missing.with_columns(group_number.alias(\"missing_group\"))\\\n",
    "         .filter(pl.col(\"missing_group\") != -1)\\\n",
    "         .group_by(\"missing_group\")\\\n",
    "         .agg(cs.ends_with(\"is_missing\").sum())\\\n",
    "         .sort(\"missing_group\"), df_query_missing_times])\\\n",
    "         .collect(streaming=True)\n",
    "        #  \n",
    "\n",
    "# TODO plot number of missing wind dir/wind speed data for each wind turbine (missing duration on x axis, turbine id on y axis, color for wind direction/wind speed)\n",
    "# fig, ax = plt.subplots(1, 1)\n",
    "# for feature_type, marker in zip(missing_data_cols, [\"o\", \"^\"]):\n",
    "#   for turbine_id in data_loader.turbine_ids:\n",
    "#     cond = df[f\"{feature_type}_{turbine_id}_is_null\"]\n",
    "#     # print(dir(df.loc[cond, \"missing_duration\"].iloc[0]))\n",
    "#     # ax.scatter(x=df.loc[cond, \"missing_duration\"].dt.seconds.to_numpy(), y=[turbine_id]*cond.sum(),\n",
    "#     ax.scatter(x=df.loc[cond, \"missing_duration\"].dt.seconds, y=df.loc[cond, f\"{feature_type}_{turbine_id}_num_nulls\"],  \n",
    "#     marker=marker, label=feature_type, s=400)\n",
    "# ax.set_title(\"Occurence of Missing Wind Speed (circle) and Wind Direction (triangle) Values vs. Missing Duration, for each Turbine.\")\n",
    "# ax.set_xlabel(\"Duration of Missing Values [s]\")\n",
    "# TODO plot missing duration on x axis, number of missing turbines on y-axis, color for wind speed vs wind direction,\n",
    "\n",
    "# TODO if more than 'missing_col_thr' columns are missing data for more than 'missing_timesteps_thr', split the dataset at the point of temporal discontinuity\n",
    "# .    else impute the values using the imputing.impute_all_assets_by_correlation function \n",
    "\n",
    "# plot time steps and turbines with missing data for wind_speed and wind_direction\n",
    "# df = pl.concat([\n",
    "#     df_query.select(pl.col(\"time\"), cs.starts_with(feature_type))\\\n",
    "#     .filter(pl.any_horizontal(pl.all().is_null()))\\\n",
    "#     .unpivot(index=\"time\", value_name=feature_type)\\\n",
    "#     .with_columns(pl.col(\"variable\").str.slice(-5).alias(\"turbine_id\"))\\\n",
    "#     .drop(\"variable\") for feature_type in [\"wind_direction\", \"wind_speed\"] ], how=\"diagonal\")\n",
    "# df = DataInspector.unpivot_dataframe(df_query)\n",
    "\n",
    "# df.filter(pl.col(\"wind_speed\").is_null() | pl.col(\"wind_direction\").is_null())\\\n",
    "#   .select(\"time\", \"turbine_id\", \"wind_speed\", \"wind_direction\")\\\n",
    "#   .with_columns(pl.when(pl.col(\"wind_speed\").is_null()).then(pl.lit(\"ws\")).otherwise(pl.lit(\"wd\")).alias(\"null_feature\"))\\\n",
    "#     .drop(\"wind_speed\", \"wind_direction\")\\\n",
    "#     .collect(streaming=True)\\\n",
    "#         .to_pandas().groupby(\"turbine_id\")[\"null_feature\"].value_counts(normalize=True).unstack(fill_value=0)\n",
    "  \n",
    "# df.filter(pl.col(\"wind_direction\").is_null()).select(\"time\", \"wind_direction\")\n",
    "# print(df.select(\"time\").to_numpy()) \n",
    "# print(df.filter(pl.col(\"wind_speed\").is_null()).select(\"turbine_id\").to_numpy())\n",
    "# import seaborn as sns\n",
    "# fig, ax = plt.subplots(1, 1)\n",
    "# sns.scatterplot(ax=ax, data=df, x=\"time\", y=\"turbine_id\", hue=\"null feature\")\n",
    "# # sns.scatterplot(x=df.filter(pl.col(\"wind_speed\").is_null()).select(\"time\").to_numpy().flatten(), y=df.filter(pl.col(\"wind_speed\").is_null()).select(\"turbine_id\").to_numpy().flatten())\n",
    "# ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputing.impute_all_assets_by_correlation\n",
    "df_query = data_filter.resolve_missing_data(df_query, features=[\"wind_speed\", \"wind_direction\", \"power_output\"], how=\"forward_fill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_query = df_query.pivot(on=\"turbine_id\", index=\"time\", values=[\"power_output\", \"nacelle_direction\", \"wind_speed\", \"wind_direction\", \"turbine_status\"]).lazy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nacelle Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and correct wind direction offsets from median wind plant wind direction for each turbine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine_ids = df_query.select(\"turbine_id\").unique().collect(streaming=True).to_numpy()[:, 0]\n",
    "\n",
    "# add the 3 degrees back to the wind direction signal\n",
    "offset = 3.0\n",
    "df_query2 = df_query.with_columns((pl.col(\"wind_direction\") + 3.0 % 360.0).alias(\"wind_direction\"))\n",
    "\n",
    "# TODO make sure that all power values are >= 0 at this point\n",
    "wd_median = DataInspector.collect_data(df_query2, [\"time\", \"turbine_id\", \"wind_direction\"]).groupby(\"time\")[\"wind_direction\"].median()\n",
    "wd_median = np.degrees(np.arctan2(np.sin(np.radians(wd_median)), np.cos(np.radians(wd_median))))\n",
    "wd_median = pd.concat([\n",
    "    DataInspector.collect_data(df_query2, [\"time\", \"turbine_id\", \"wind_direction\", \"power_output\"])\\\n",
    "    .pivot(index=\"time\", columns=\"turbine_id\", values=\"power_output\")\\\n",
    "        .rename(columns={old_col: f\"power_output_{old_col}\" for old_col in turbine_ids}), \n",
    "    wd_median], axis=1)\n",
    "\n",
    "yaw_median = DataInspector.collect_data(df_query2, [\"time\", \"turbine_id\", \"nacelle_direction\"]).groupby(\"time\")[\"nacelle_direction\"].median()\n",
    "yaw_median = np.degrees(np.arctan2(np.sin(np.radians(yaw_median)), np.cos(np.radians(yaw_median))))\n",
    "yaw_median = pd.concat([\n",
    "    DataInspector.collect_data(df_query2, [\"time\", \"turbine_id\", \"wind_direction\", \"power_output\"])\\\n",
    "    .pivot(index=\"time\", columns=\"turbine_id\", values=\"power_output\")\\\n",
    "        .rename(columns={old_col: f\"power_output_{old_col}\" for old_col in turbine_ids}), \n",
    "    yaw_median], axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for turbine_id in turbine_ids:\n",
    "    df = DataInspector.collect_data(df=df_query2, \n",
    "                        features=[\"time\", \"turbine_id\", \"wind_direction\", \"power_output\"], \n",
    "                        mask=((pl.col(\"turbine_id\") == turbine_id) & (pl.col(\"power_output\") >= 0)))\n",
    "                        \n",
    "    ax.plot(df[\"time\"], DataFilter.wrap_180(\n",
    "                        df.pivot(index=\"time\", columns=\"turbine_id\", values=\"wind_direction\").values \n",
    "                        - wd_median.loc[(wd_median[f\"power_output_{turbine_id}\"] >= 0), \"wind_direction\"].values[:, np.newaxis]),\n",
    "                        label=f\"{turbine_id}\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Wind Direction - Median Wind Direction (deg)\")\n",
    "\n",
    "ax.set_title(\"Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_query2.select([\"time\", \"turbine_id\", \"wind_direction\", \"power_output\", \"nacelle_direction\"]).filter(((pl.col(\"turbine_id\") == turbine_id) & (pl.col(\"power_output\") >= 0))).collect(streaming=True)\n",
    "# DataInspector.collect_data(df=df_query2, \n",
    "#                         features=[\"time\", \"turbine_id\", \"wind_direction\", \"power_output\", \"nacelle_direction\"], \n",
    "#                         mask=((pl.col(\"turbine_id\") == turbine_id) & (pl.col(\"power_output\") >= 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_offsets = {\"turbine_id\": [], \"northing_bias\": []}\n",
    "\n",
    "# remove biases from median direction\n",
    "for turbine_id in turbine_ids:\n",
    "    df = DataInspector.collect_data(df=df_query2, \n",
    "                        features=[\"time\", \"turbine_id\", \"wind_direction\", \"power_output\", \"nacelle_direction\"], \n",
    "                        mask=((pl.col(\"turbine_id\") == turbine_id) & (pl.col(\"power_output\") >= 0)))\n",
    "\n",
    "    if (turbine_id == f\"wt_001\"):\n",
    "        wd_bias = DataFilter.wrap_180(DataFilter.circ_mean(df.loc[(df['time'] >= \"2021-08-03 19:20\"), \"wind_direction\"] \n",
    "            - wd_median.loc[(df['time'] >= \"2021-08-03 19:20\") & (wd_median[f'power_output_{turbine_id}'] >= 0)]))\n",
    "        yaw_bias = DataFilter.wrap_180(DataFilter.circ_mean(df.loc[(df['time'] >= \"2021-08-03 19:20\"), \"nacelle_direction\"] \n",
    "        - yaw_median.loc[(df['time'] >= \"2021-08-03 19:20\") & (yaw_median[f'power_output{turbine_id}' % i] >= 0)]))\n",
    "    else:\n",
    "        wd_bias = DataFilter.wrap_180(DataFilter.circ_mean(df[\"wind_direction\"] - wd_median.loc[wd_median[f\"power_output_{turbine_id}\"] >= 0, \"wind_direction\"]))\n",
    "        yaw_bias = DataFilter.wrap_180(DataFilter.circ_mean(df[\"nacelle_direction\"] - yaw_median.loc[yaw_median[f\"power_output_{turbine_id}\"] >= 0, \"nacelle_direction\"]))\n",
    "\n",
    "    df_offsets[\"turbine_id\"].append(turbine_id)\n",
    "    df_offsets[\"northing_bias\"].append(np.round(0.5 * (wd_bias + yaw_bias), 2))\n",
    "        \n",
    "    if (turbine_id != f\"wt_040\"):\n",
    "        df.loc[df[\"turbine_id\"] == turbine_id, \"wind_direction\"] = (df.loc[df[\"turbine_id\"] == turbine_id, \"wind_direction\"] - 0.5 * (wd_bias + yaw_bias)) % 360\n",
    "        df.loc[df[\"turbine_id\"] == turbine_id, \"nacelle_direction\"] = (df.loc[df[\"turbine_id\"] == turbine_id, \"nacelle_direction\"] - 0.5 * (wd_bias + yaw_bias)) % 360\n",
    "        print(f\"Turbine {turbine_id} bias from median wind direction: {np.round(0.5 * (wd_bias + yaw_bias), 2)} deg.\")\n",
    "\n",
    "df_offsets = pd.DataFrame(df_offsets)\n",
    "# handle special case of turbine 39 with a couple change points\n",
    "\"\"\"\n",
    "tid = \"wd_040\"\n",
    "df = DataInspector.collect_data(df=df_query2, \n",
    "                        features=[\"time\", \"turbine_id\", \"wind_direction\", \"power_output\", \"nacelle_direction\"], \n",
    "                        mask=((pl.col(\"turbine_id\") == tid) & (pl.col(\"power_output\") >= 0)))\n",
    "wd_bias_1 = DataFilter.wrap_180(DataFilter.circ_mean(df.loc[\n",
    "    (df['time'] <= \"2021-06-09 19:30\"), \"wind_direction\"].values \\\n",
    "        - wd_median.loc[\n",
    "            (wd_median['time'] <= \"2021-06-09 19:30\") \n",
    "        & (wd_median[f\"power_output_{tid}\"] >= 0), \"wind_direction\"].values))\n",
    "\n",
    "wd_bias_2 = DataFilter.wrap_180(DataFilter.circ_mean(df.loc[\n",
    "    (df['time'] >= \"2021-06-09 19:40\")\n",
    "    & (df['time'] <= \"2021-09-14 19:50\"), \"wind_direction\"].values \\\n",
    "        - wd_median.loc[\n",
    "            (wd_median['time'] >= \"2021-06-09 19:30\")\n",
    "            & (wd_median['time'] <= \"2021-09-14 19:50\")   \n",
    "        & (wd_median[f\"power_output_{tid}\"] >= 0), \"wind_direction\"].values))\n",
    "\n",
    "wd_bias_3 = DataFilter.wrap_180(DataFilter.circ_mean(df.loc[\n",
    "    (df['time'] >= \"2021-09-14 20:00\"), \"wind_direction\"].values \\\n",
    "        - wd_median.loc[\n",
    "            (wd_median['time'] >= \"2021-09-14 20:00\")\n",
    "        & (wd_median[f\"power_output_{tid}\"] >= 0), \"wind_direction\"].values))\n",
    "\n",
    "yaw_bias_1 = DataFilter.wrap_180(DataFilter.circ_mean(df.loc[\n",
    "    (df['time'] <= \"2021-06-09 19:30\"), \"nacelle_direction\"].values \\\n",
    "        - yaw_median.loc[\n",
    "            (yaw_median['time'] <= \"2021-06-09 19:30\") \n",
    "        & (yaw_median[f\"power_output_{tid}\"] >= 0), \"wind_direction\"].values))\n",
    "\n",
    "yaw_bias_2 = DataFilter.wrap_180(DataFilter.circ_mean(df.loc[\n",
    "    (df['time'] >= \"2021-06-09 19:40\")\n",
    "    & (df['time'] <= \"2021-09-14 19:50\"), \"nacelle_direction\"].values \\\n",
    "        - yaw_median.loc[\n",
    "            (yaw_median['time'] >= \"2021-06-09 19:30\")\n",
    "            & (yaw_median['time'] <= \"2021-09-14 19:50\")   \n",
    "        & (yaw_median[f\"power_output_{tid}\"] >= 0), \"wind_direction\"].values))\n",
    "\n",
    "yaw_bias_3 = DataFilter.wrap_180(DataFilter.circ_mean(df.loc[\n",
    "    (df['time'] >= \"2021-09-14 20:00\"), \"nacelle_direction\"].values \\\n",
    "        - yaw_median.loc[\n",
    "            (yaw_median['time'] >= \"2021-09-14 20:00\")\n",
    "        & (yaw_median[f\"power_output_{tid}\"] >= 0), \"wind_direction\"].values))\n",
    "\n",
    "cond = (df['time'] <= \"2021-06-09 19:30\")\n",
    "df.loc[cond, \"wind_direction\"] = (df.loc[cond, \"wind_direction\"] - 0.5 * (wd_bias_1 + yaw_bias_1)) % 360\n",
    "df.loc[cond, \"nacelle_direction\"] = (df[cond, \"nacelle_direction\"] - 0.5 * (wd_bias_1 + yaw_bias_1)) % 360\n",
    "\n",
    "cond = (df['time'] >= \"2021-06-09 19:40\") & (df['time'] <= \"2021-09-14 19:50\")\n",
    "df.loc[cond, \"wind_direction\"] = (df.loc[cond, \"wind_direction\"] - 0.5 * (wd_bias_2 + yaw_bias_2)) % 360\n",
    "df.loc[cond, \"nacelle_direction\"] = (df.loc[cond, \"nacelle_direction\"] - 0.5 * (wd_bias_2 + yaw_bias_2)) % 360\n",
    "\n",
    "cond = (df['time'] >= \"2021-09-14 20:00\")\n",
    "df.loc[cond, \"wind_direction\"] = (df.loc[cond, \"wind_direction\"] - 0.5 * (wd_bias_3 + yaw_bias_3)) % 360\n",
    "df.loc[cond, \"nacelle_direction\"] = (df.loc[cond, \"nacelle_direction\"] - 0.5 * (wd_bias_3 + yaw_bias_3)) % 360\n",
    "\n",
    "print(\"Biases from median wind direction for turbine 39:\")\n",
    "\n",
    "print(f\"wd_bias_1: {wd_bias_1}\")\n",
    "print(f\"wd_bias_2: {wd_bias_2}\")\n",
    "print(f\"wd_bias_3: {wd_bias_3}\")\n",
    "\n",
    "print(f\"yaw_bias_1: {yaw_bias_1}\")\n",
    "print(f\"yaw_bias_2: {yaw_bias_2}\")\n",
    "print(f\"yaw_bias_3: {yaw_bias_3}\")\n",
    "\n",
    "plt.figure()\n",
    "for turbine_id in turbine_ids:\n",
    "    plt.plot(df[\"time\"], \n",
    "    DataFilter.wrap_180(df[\"wind_direction\"].values - wd_median.loc[wd_median[f\"power_output_{turbine_id}\"] >= 0, \"wind_direction\"].values))\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Wind Direction - Median Wind Direction (deg)\")\n",
    "plt.title(\"Corrected\")\n",
    "\n",
    "# specific time of changepoints for turbine 39: 6/9 19:35:55; 9/14 19:55:02\n",
    "\"\"\"\n",
    "# make sure we have corrected the bias between wind direction and yaw position by adding 3 deg. to the wind direction\n",
    "bias = 0\n",
    "for turbine_id in turbine_ids:\n",
    "    df = DataInspector.collect_data(df=df_query2, \n",
    "                        features=[\"time\", \"turbine_id\", \"wind_direction\", \"power_output\", \"nacelle_direction\"], \n",
    "                        mask=((pl.col(\"turbine_id\") == turbine_id) & (pl.col(\"power_output\") >= 0)))[[\"wind_direction\", \"nacelle_direction\"]]\n",
    "    bias += DataFilter.wrap_180(DataFilter.circ_mean(df[\"wind_direction\"] - df[\"nacelle_direction\"]))\n",
    "    \n",
    "print(f\"Average Bias = {bias / len(turbine_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find offset to true North using wake loss profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Optimization function for finding waked direction\n",
    "def gauss_corr(gauss_params, power_ratio):\n",
    "    xs = np.array(range(-int((len(power_ratio) - 1) / 2), int((len(power_ratio) + 1) / 2), 1))\n",
    "    gauss = -1 * gauss_params[2] * np.exp(-0.5 * ((xs-gauss_params[0]) / gauss_params[1])**2) + 1.\n",
    "    return -1 * np.corrcoef(gauss, power_ratio)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Find offsets between direction of alignment between pairs of turbines \n",
    "# and direction of peak wake losses. Use the average offset found this way \n",
    "# to identify the Northing correction that should be applied to all turbines \n",
    "# in the wind farm.\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from floris import FlorisModel\n",
    "fi = FlorisModel(data_inspector.farm_input_filepath)\n",
    "\n",
    "p_min = 100\n",
    "p_max = 2500\n",
    "\n",
    "prat_hfwdth = 30\n",
    "\n",
    "prat_turbine_pairs = [(61,60), (51,50), (43,42), (41,40), (18,19), (34,33), (17,16), (21,22), (87,86), (62,63), (32,33), (59,60), (42,43)]\n",
    "\n",
    "dir_offsets = []\n",
    "\n",
    "for i in range(len(prat_turbine_pairs)):\n",
    "    i_up = prat_turbine_pairs[i][0]\n",
    "    i_down = prat_turbine_pairs[i][1]\n",
    "\n",
    "    dir_align = np.degrees(np.arctan2(fi.layout_x[i_up] - fi.layout_x[i_down], fi.layout_y[i_up] - fi.layout_y[i_down])) % 360\n",
    "\n",
    "    # df_sub = df_10min.loc[(df_10min['pow_%03d' % i_up] >= p_min) & (df_10min['pow_%03d' % i_up] <= p_max) & (df_10min['pow_%03d' % i_down] >= 0)]\n",
    "\n",
    "    df_sub = df_query.filter(((pl.col(\"turbine_id\") == f'wt{i_up:03d}') \n",
    "                              & (pl.col(\"power_output\") >= p_min) \n",
    "                              & (pl.col(\"power_output\") <= p_max)) \n",
    "                  | ((pl.col(\"turbine_id\") == f'wt{i_down:03d}') \n",
    "                     & (pl.col(\"power_output\") >= 0)))\n",
    "    print(df_query.filter(pl.col(\"turbine_id\") == f'wt{i_up:03d}').collect(streaming=True))\n",
    "    \n",
    "    # df_sub.loc[df_sub['wd_%03d' % i_up] >= 359.5,'wd_%03d' % i_up] = df_sub.loc[df_sub['wd_%03d' % i_up] >= 359.5,'wd_%03d' % i_up] - 360.0\n",
    "    df_sub = df_sub.with_columns(pl.when((pl.col(\"turbine_id\") == f'wt{i_up:03d}') & (pl.col(\"wind_direction\") >= 359.5))\\\n",
    "                                     .then(pl.col(\"wind_direction\") - 360.0)\\\n",
    "                                     .otherwise(pl.col(\"wind_direction\"))\\\n",
    "                                     .alias(\"wind_direction\"))\n",
    "    # df_sub[\"wd_round\"] = df_sub[f'wd_{i_up:03d}'].round()\n",
    "    df_sub = df_sub.with_columns(pl.col(\"wind_direction\").round().alias(\"wind_direction_round\"))\n",
    "\n",
    "    df_sub = df_sub.group_by(\"wind_direction_round\").mean().collect(streaming=True).to_pandas()\n",
    "\n",
    "    p_ratio = df_sub.loc[df_sub[\"turbine_id\"] == f\"wt{i_down:03d}\", f'power_output'] \\\n",
    "        / df_sub.loc[df_sub[\"turbine_id\"] == f\"wt{i_up:03d}\", f'power_output']\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(p_ratio, label=\"_nolegend_\")\n",
    "    plt.plot(dir_align * np.ones(2),[0,1.25], 'k--', label=\"Direction of Alignment\")\n",
    "    plt.grid()\n",
    "\n",
    "    nadir = np.argmin(p_ratio[np.arange(int(np.round(dir_align)) - prat_hfwdth,int(np.round(dir_align)) + prat_hfwdth + 1) % 360])\n",
    "    nadir = nadir + int(np.round(dir_align)) - prat_hfwdth\n",
    "\n",
    "    opt_gauss_params = minimize(gauss_corr, [0, 5.0, 1.0], args=(p_ratio[np.arange(nadir-prat_hfwdth,nadir + prat_hfwdth + 1) % 360]),method='SLSQP')\n",
    "\n",
    "    xs = np.array(range(-int((60 - 1) / 2),int((60 + 1) / 2),1))\n",
    "    gauss = -1 * opt_gauss_params.x[2] * np.exp(-0.5 * ((xs - opt_gauss_params.x[0]) / opt_gauss_params.x[1])**2) + 1.\n",
    "\n",
    "    plt.plot(xs + nadir, gauss,'k',label=\"_nolegend_\")\n",
    "    plt.plot(2 * [nadir + opt_gauss_params.x[0]], [0,1.25], 'r--',label=\"Direction of Measured Wake Center\")\n",
    "    plt.title(f\"Turbine Pair: ({i_up}, {i_down})\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Wind Direction (deg)\")\n",
    "    plt.ylabel(\"Power Ratio (-)\")\n",
    "    \n",
    "    dir_offset = DataFilter.wrap_180(nadir + opt_gauss_params.x[0] - dir_align)\n",
    "    print(dir_offset)\n",
    "\n",
    "    dir_offsets = dir_offsets + [dir_offset]\n",
    "\n",
    "print(f\"Mean offset = {np.mean(dir_offsets)}\")\n",
    "print(f\"Std. Dev. = {np.std(dir_offsets)}\")\n",
    "print(f\"Min. = {np.min(dir_offsets)}\")\n",
    "print(f\"Max. = {np.max(dir_offsets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wind_forecasting_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
